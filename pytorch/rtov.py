# -*- coding: utf-8 -*-
"""tch_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EdPbNRZ6YJZGhSTW-h-h9gCmvd9R4mes
"""

import cv2
cv2_imshow = lambda img: cv2.imshow('', img)
import matplotlib.pyplot as plt
import numpy as np

from enum import IntEnum, auto
from typing import Union, Optional, Sequence, Generator

# Utils {{{

class Shapes(IntEnum):
    Line = 0
    Triangle = 1
    Rect = 2

Number = Union[int, float]

class Vec2:
    def __init__(self, x, y) -> None:
        self.x = x
        self.y = y

class Vec3:
    def __init__(self, x, y, z) -> None:
        self.x = x
        self.y = y
        self.z = z

    def as_tuple(self) -> tuple:
        return self.x, self.y, self.z

# }}}

# Data {{{

class DefaultPoints:
    @staticmethod
    def line(dim: Vec2, random: bool = True) -> np.ndarray:
        pts = np.zeros((2, 2), dtype=np.int32)
        if random:
            rng = np.random.default_rng()
            pts[:, 0] = rng.integers(
                low = 0, high = dim.x, size = 2)    # x values
            pts[:, 1] = rng.integers(
                low = 0, high = dim.y, size = 2)    # y values
            return pts

        # Diagonal line through the image from (0, 0)
        pts[0, 0] = dim.x
        pts[0, 1] = dim.y
        return pts

    @staticmethod
    def triangle(dim: Vec2, random: bool = True) -> np.ndarray:
        pts = np.zeros((3, 2), dtype=np.int32)

        # Random three points
        if random:
            rng = np.random.default_rng()
            pts[:, 0] = rng.integers(
                low = 0, high = dim.x, size = 3)    # x values
            pts[:, 1] = rng.integers(
                low = 0, high = dim.y, size = 3)    # y values
            return pts

        # (More or less) regular triangle
        pts[0, 0] = dim.x // 4      # Bottom left
        pts[0, 1] = dim.y // 4
        pts[1, 0] = dim.x * 3 // 4  # Bottom right
        pts[1, 1] = dim.y // 4
        pts[2, 0] = dim.x // 2      # Top mid
        pts[2, 1] = dim.y * 3 // 4
        return pts

    @staticmethod
    def rectangle(dim: Vec2, random: bool = True) -> np.ndarray:
        pts = np.zeros((4, 2), dtype=np.int32)

        if random:
            rng = np.random.default_rng()
            # Top left corner
            pts[0, 0] = rng.integers(0, dim.x * 3 // 4)  # Leave enough free space
            pts[0, 1] = rng.integers(0, dim.y * 3 // 4)
            # Bottom left corner, spans a rect with random height
            pts[1, 0] = pts[0, 0]
            pts[1, 1] = rng.integers(pts[0, 1], dim.y)
            # Top right corner -> random width
            pts[3, 0] = rng.integers(pts[0, 0], dim.x)
            pts[3, 1] = pts[0, 1]
            # Bottom right corner
            pts[2, 0] = pts[3, 0]
            pts[2, 1] = pts[1, 1]
            return pts

        # Regular rectangle
        pts[[0, 1], 0] = dim.x // 4     # Left edge
        pts[[0, 3], 1] = dim.y // 4     # Top edge
        pts[[2, 3], 0] = dim.x * 3 // 4 # Right edge
        pts[[1, 2], 1] = dim.y * 3 // 4 # Bottom edge
        return pts


def draw_on_image(img: np.ndarray, shape: Shapes | int, color: int = 0) -> np.ndarray:
    """Mutates `img` in-place"""
    if shape == Shapes.Line:
        pts = DefaultPoints.line(
            Vec2(img.shape[0], img.shape[1]), random=True)
        cv2.line(img, pts[0], pts[1], color)
        return pts
    elif shape == Shapes.Triangle:
        pts = DefaultPoints.triangle(
            Vec2(img.shape[0], img.shape[1]), random=True)
    elif shape == Shapes.Rect:
        pts = DefaultPoints.rectangle(
            Vec2(img.shape[0], img.shape[1]), random=True)
    else:
        raise ValueError("Unknown or unimplemented shape: {}".format(shape))
    cv2.fillPoly(img, [pts], color=color)
    return pts

# }}}

# Model {{{

# %pip install torch

import torch
from torch import nn
from torchvision import transforms

class MainModel(nn.Module):
    def __init__(self, img_dim: Vec3, batch_size: int = 32) -> None:
        super(MainModel, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=16,
                      kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2), # Output shape: (16, 50, 50)
            nn.Conv2d(in_channels=16, out_channels=32,
                      kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2), # Output shape: (32, 25, 25)
            ) # Output shape: (32, 25, 25)
        #   32: Channels
        #   25x25: Resulting width and height
        self.fc_color = nn.Linear(32 * 25 * 25,
                                  out_features = 3)  # 3 for the RGB channels
        self.fc_shape = nn.Sequential(
            nn.Linear(32 * 25 * 25,
                      out_features = 128, bias = True),
            nn.ReLU(),
            nn.Linear(128, len(Shapes)),
        )
        self.fc_first_point = nn.Sequential(
            nn.Linear(32 * 25 * 25,
                      out_features = 128, bias = True),
            nn.ReLU(),
            nn.Linear(128, 2)       # 2: x and y coordinate
        )

    def forward(self, x):
        # Here we need the shape
        #       (batch_size channels height width) i. e. (32 3 100 100)
        # x = x.view(x.size(0), # Batch size
        #            x.size(3), # Channels
        #            x.size(1), # Height
        #            x.size(2)) # Width
        features = self.conv_layers(x)
        features = features.view(x.size(0), -1)
        shape = self.fc_shape(features)
        #color = self.fc_color(features)
        #first_point = self.fc_first_point(features)
        return shape

# }}}

# Glue {{{

import torch
from torch.utils.data import Dataset
import torch.optim as optim
from torch.utils.data import DataLoader

class LazyDataset(Dataset):
    def __init__(self, img_dim: Vec3, num_samples, transform=None):
        self.num_samples = num_samples
        self.transform = transform
        self.features = np.zeros(img_dim.as_tuple(), dtype=np.float32)
        self.tensor = np.zeros((img_dim.z, img_dim.x, img_dim.y), dtype=np.float32)

    def __len__(self):
        return self.num_samples

    def __getitem__(self, i):
        self.features[:] = np.full(self.features.shape, 255)    # Overwrite the memory directly to (hopefully) reduce memory => fewer GC cycles
        shape = np.random.default_rng().integers(len(Shapes))
        pts = draw_on_image(self.features, shape, color=0)
        if self.transform:
            self.tensor[:] = self.transform(self.features)
        # TODO: Calc size + first point
        return self.tensor, shape

transform_fn = transforms.Compose([
    #transforms.Resize((100, 100, 3)),
    #transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally
    transforms.ToTensor(),
    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image
])

# }}}

# Training {{{

import torch.optim as optim

# Define your model
model = MainModel(img_dim=Vec3(100, 100, 3), batch_size=32)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0005)
num_epochs = 4

# Data generation and preprocessing
train_dataset = LazyDataset(
    img_dim = Vec3(100, 100, 3),
    num_samples = 50 * 32,
    transform = transform_fn,
)
dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)

train_losses = np.zeros(num_epochs * len(dataloader))
train_accuracies = np.zeros(num_epochs * len(dataloader))

# Training loop
for epoch in range(num_epochs):
    running_loss = 0.0
    for i, (inputs, labels) in enumerate(dataloader):
        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = model(inputs)

        # Calculate loss
        loss = criterion(outputs, labels)

        # Back propagation and optimization
        loss.backward()
        optimizer.step()

        loss = loss.item()
        running_loss += loss
        train_losses[epoch * len(dataloader) + i] = loss
        # train_accuracies[epoch * len(dataloader) + i] = optimizer.state_dict()

    # Print loss at the end of each epoch
    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(dataloader)}')

# Save the trained model
torch.save(model.state_dict(), 'trained_model.pth')


# Plot loss curves
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(train_losses, label="Train")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

# Plot accuracy curves
# plt.subplot(1, 2, 2)
# plt.plot(train_accuracies, label="Train")
# plt.xlabel("Epoch")
# plt.ylabel("Accuracy")
# plt.legend()

plt.show()

# }}}

# Visualization {{{
rows, cols = 3, 3

model.eval()

test_dataset = LazyDataset(
    img_dim = Vec3(100, 100, 3),
    num_samples = 32,
    transform = transform_fn,
)
dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)

fig, axes = plt.subplots(rows, cols, figsize=(10, 5))
for i in range (cols * rows):
    ax = axes[i // cols, i % cols]
    ax.axis('off')

    # Take the first batch
    imgs, labels = next(iter(dataloader))
    predictions = model(imgs)

    # Take the last one of this batch, because it's the only one with an image
    pred = predictions[-1].argmax()
    img, label = imgs[-1], labels[-1]

    # CHW -> HWC (32, 100, 100, 3)
    img = np.transpose(img, (1, 2, 0))

    # Display the image and prediction
    ax.imshow(img)
    ax.set_title(f'{label} -> {pred}')
    print(f'{label} -> {predictions[-1]}')

plt.tight_layout()
plt.show()


## Note for me:
#    Because the memory of the images are overwritten, we can't just show
#    them afterwards. There is only the last image shown.

# }}}

# Analytics {{{

# # %pip install torchviz
# from torchviz import make_dot

# Visualize the net

# model = MainModel(Vec3(100, 100, 3), batch_size=32)

# img = np.ones((100, 100, 3), dtype=np.ubyte)

# x = transform_fn(img)
# y = model(x)

# make_dot(y.mean(), params=dict(model.named_parameters()))
# }}}
